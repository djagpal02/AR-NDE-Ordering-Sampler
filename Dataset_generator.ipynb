{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c5ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from Made import Made, arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0753337",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6907e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(args, seed, n_samples, path, device):\n",
    "    # Set seed\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Set ordering:\n",
    "    ordering = np.random.permutation(args.nin)\n",
    "    \n",
    "    xtr = torch.randn(5000,dims).to(device)\n",
    "    xva = torch.randn(1000,dims).to(device)\n",
    "\n",
    "    M = Made(args, device, 'Params/' + path, preset_ordering = True, ordering=ordering)\n",
    "    \n",
    "    M.train(xtr,xva,max_iter_ = 100, convergence_criteron = 0.001, early_stop = 30, upto=1)\n",
    "    \n",
    "    del xtr\n",
    "    del xva\n",
    "\n",
    "    return (M.sample(n_samples).detach().numpy(), ordering)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14881869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afb487bc",
   "metadata": {},
   "source": [
    "# Dataset 1, Binary low dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "607d03ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "test epoch average loss: 44.140430\n",
      "train epoch average loss: 40.077231\n",
      "epoch 2\n",
      "test epoch average loss: 32.494156\n",
      "train epoch average loss: 22.336306\n",
      "epoch 3\n",
      "test epoch average loss: 13.656196\n",
      "train epoch average loss: 10.317438\n",
      "epoch 4\n",
      "test epoch average loss: 6.598769\n",
      "train epoch average loss: 5.550771\n",
      "epoch 5\n",
      "test epoch average loss: 3.242537\n",
      "train epoch average loss: 2.882832\n",
      "epoch 6\n",
      "test epoch average loss: 1.167611\n",
      "train epoch average loss: 0.966110\n",
      "epoch 7\n",
      "test epoch average loss: -0.500813\n",
      "train epoch average loss: -0.815885\n",
      "epoch 8\n",
      "test epoch average loss: -2.129601\n",
      "train epoch average loss: -2.660235\n",
      "epoch 9\n",
      "test epoch average loss: -3.858475\n",
      "train epoch average loss: -4.619667\n",
      "epoch 10\n",
      "test epoch average loss: -5.834384\n",
      "train epoch average loss: -6.866955\n",
      "epoch 11\n",
      "test epoch average loss: -8.285321\n",
      "train epoch average loss: -9.622225\n",
      "epoch 12\n",
      "test epoch average loss: -11.364456\n",
      "train epoch average loss: -13.116072\n",
      "epoch 13\n",
      "test epoch average loss: -15.355675\n",
      "train epoch average loss: -17.587535\n",
      "epoch 14\n",
      "test epoch average loss: -20.490870\n",
      "train epoch average loss: -23.303366\n",
      "epoch 15\n",
      "test epoch average loss: -27.147966\n",
      "train epoch average loss: -30.563521\n",
      "epoch 16\n",
      "test epoch average loss: -35.715618\n",
      "train epoch average loss: -39.681483\n",
      "epoch 17\n",
      "test epoch average loss: -46.692562\n",
      "train epoch average loss: -51.033145\n",
      "epoch 18\n",
      "test epoch average loss: -60.442383\n",
      "train epoch average loss: -64.944914\n",
      "epoch 19\n",
      "test epoch average loss: -77.480118\n",
      "train epoch average loss: -81.737231\n",
      "epoch 20\n",
      "test epoch average loss: -98.052849\n",
      "train epoch average loss: -101.731379\n",
      "epoch 21\n",
      "test epoch average loss: -122.706757\n",
      "train epoch average loss: -125.232779\n",
      "epoch 22\n",
      "test epoch average loss: -151.409973\n",
      "train epoch average loss: -152.512151\n",
      "epoch 23\n",
      "test epoch average loss: -185.012283\n",
      "train epoch average loss: -183.910791\n",
      "epoch 24\n",
      "test epoch average loss: -223.694717\n",
      "train epoch average loss: -219.692145\n",
      "epoch 25\n",
      "test epoch average loss: -267.536804\n",
      "train epoch average loss: -260.100146\n",
      "epoch 26\n",
      "test epoch average loss: -316.758484\n",
      "train epoch average loss: -305.303835\n",
      "epoch 27\n",
      "test epoch average loss: -371.628143\n",
      "train epoch average loss: -355.547256\n",
      "epoch 28\n",
      "test epoch average loss: -432.621002\n",
      "train epoch average loss: -411.024248\n",
      "epoch 29\n",
      "test epoch average loss: -499.893616\n",
      "train epoch average loss: -471.964457\n",
      "epoch 30\n",
      "test epoch average loss: -573.860046\n",
      "train epoch average loss: -538.546974\n",
      "epoch 31\n",
      "test epoch average loss: -654.901367\n",
      "train epoch average loss: -610.867849\n",
      "epoch 32\n",
      "test epoch average loss: -742.722534\n",
      "train epoch average loss: -689.129836\n",
      "epoch 33\n",
      "test epoch average loss: -837.821716\n",
      "train epoch average loss: -773.543949\n",
      "epoch 34\n",
      "test epoch average loss: -940.114380\n",
      "train epoch average loss: -864.155748\n",
      "epoch 35\n",
      "test epoch average loss: -1049.904541\n",
      "train epoch average loss: -961.231763\n",
      "epoch 36\n",
      "test epoch average loss: -1166.611938\n",
      "train epoch average loss: -1064.748465\n",
      "epoch 37\n",
      "test epoch average loss: -1292.546631\n",
      "train epoch average loss: -1174.935143\n",
      "epoch 38\n",
      "test epoch average loss: -1426.371216\n",
      "train epoch average loss: -1291.735437\n",
      "epoch 39\n",
      "test epoch average loss: -1568.351318\n",
      "train epoch average loss: -1415.500899\n",
      "epoch 40\n",
      "test epoch average loss: -1718.322754\n",
      "train epoch average loss: -1545.997323\n",
      "epoch 41\n",
      "test epoch average loss: -1878.307007\n",
      "train epoch average loss: -1684.066926\n",
      "epoch 42\n",
      "test epoch average loss: -2045.131958\n",
      "train epoch average loss: -1828.655440\n",
      "epoch 43\n",
      "test epoch average loss: -2222.612549\n",
      "train epoch average loss: -1981.525807\n",
      "epoch 44\n",
      "test epoch average loss: -2405.465576\n",
      "train epoch average loss: -2140.507111\n",
      "epoch 45\n",
      "test epoch average loss: -2600.610840\n",
      "train epoch average loss: -2308.190988\n",
      "epoch 46\n",
      "test epoch average loss: -2801.716309\n",
      "train epoch average loss: -2412.929198\n",
      "epoch 47\n",
      "test epoch average loss: -2820.861084\n",
      "train epoch average loss: -2430.484193\n",
      "epoch 48\n",
      "test epoch average loss: -2841.013672\n",
      "train epoch average loss: -2447.223134\n",
      "epoch 49\n",
      "test epoch average loss: -2860.352539\n",
      "train epoch average loss: -2463.453165\n",
      "epoch 50\n",
      "test epoch average loss: -2879.295654\n",
      "train epoch average loss: -2479.240819\n",
      "epoch 51\n",
      "test epoch average loss: -2897.868896\n",
      "train epoch average loss: -2494.654280\n",
      "epoch 52\n",
      "test epoch average loss: -2916.012939\n",
      "train epoch average loss: -2509.733745\n",
      "epoch 53\n",
      "test epoch average loss: -2933.712158\n",
      "train epoch average loss: -2524.523124\n",
      "epoch 54\n",
      "test epoch average loss: -2951.122314\n",
      "train epoch average loss: -2539.067562\n",
      "epoch 55\n",
      "test epoch average loss: -2968.168457\n",
      "train epoch average loss: -2553.376420\n",
      "epoch 56\n",
      "test epoch average loss: -2984.885986\n",
      "train epoch average loss: -2567.472548\n",
      "epoch 57\n",
      "test epoch average loss: -3001.421387\n",
      "train epoch average loss: -2581.416539\n",
      "epoch 58\n",
      "test epoch average loss: -3017.805664\n",
      "train epoch average loss: -2595.224981\n",
      "epoch 59\n",
      "test epoch average loss: -3034.055664\n",
      "train epoch average loss: -2608.913767\n",
      "epoch 60\n",
      "test epoch average loss: -3050.186279\n",
      "train epoch average loss: -2622.496426\n",
      "epoch 61\n",
      "test epoch average loss: -3066.215820\n",
      "train epoch average loss: -2635.989146\n",
      "epoch 62\n",
      "test epoch average loss: -3082.149658\n",
      "train epoch average loss: -2649.398412\n",
      "epoch 63\n",
      "test epoch average loss: -3097.998779\n",
      "train epoch average loss: -2662.734782\n",
      "epoch 64\n",
      "test epoch average loss: -3113.796387\n",
      "train epoch average loss: -2676.008344\n",
      "epoch 65\n",
      "test epoch average loss: -3129.512451\n",
      "train epoch average loss: -2689.224859\n",
      "epoch 66\n",
      "test epoch average loss: -3145.184326\n",
      "train epoch average loss: -2702.392882\n",
      "epoch 67\n",
      "test epoch average loss: -3160.772949\n",
      "train epoch average loss: -2715.520296\n",
      "epoch 68\n",
      "test epoch average loss: -3176.333008\n",
      "train epoch average loss: -2728.609069\n",
      "epoch 69\n",
      "test epoch average loss: -3191.830566\n",
      "train epoch average loss: -2741.663877\n",
      "epoch 70\n",
      "test epoch average loss: -3207.308594\n",
      "train epoch average loss: -2754.691057\n",
      "epoch 71\n",
      "test epoch average loss: -3222.747314\n",
      "train epoch average loss: -2767.694691\n",
      "epoch 72\n",
      "test epoch average loss: -3238.160889\n",
      "train epoch average loss: -2780.679296\n",
      "epoch 73\n",
      "test epoch average loss: -3253.562988\n",
      "train epoch average loss: -2793.648102\n",
      "epoch 74\n",
      "test epoch average loss: -3268.954346\n",
      "train epoch average loss: -2806.602859\n",
      "epoch 75\n",
      "test epoch average loss: -3284.352783\n",
      "train epoch average loss: -2819.547364\n",
      "epoch 76\n",
      "test epoch average loss: -3299.740967\n",
      "train epoch average loss: -2832.483967\n",
      "epoch 77\n",
      "test epoch average loss: -3315.141113\n",
      "train epoch average loss: -2845.415865\n",
      "epoch 78\n",
      "test epoch average loss: -3330.521484\n",
      "train epoch average loss: -2858.348548\n",
      "epoch 79\n",
      "test epoch average loss: -3345.916748\n",
      "train epoch average loss: -2871.278877\n",
      "epoch 80\n",
      "test epoch average loss: -3361.319092\n",
      "train epoch average loss: -2884.212247\n",
      "epoch 81\n",
      "test epoch average loss: -3376.714844\n",
      "train epoch average loss: -2897.150717\n",
      "epoch 82\n",
      "test epoch average loss: -3392.142334\n",
      "train epoch average loss: -2910.095433\n",
      "epoch 83\n",
      "test epoch average loss: -3407.562500\n",
      "train epoch average loss: -2923.048928\n",
      "epoch 84\n",
      "test epoch average loss: -3423.015625\n",
      "train epoch average loss: -2936.012316\n",
      "epoch 85\n",
      "test epoch average loss: -3438.479004\n",
      "train epoch average loss: -2948.987203\n",
      "epoch 86\n",
      "test epoch average loss: -3453.941895\n",
      "train epoch average loss: -2961.975740\n",
      "epoch 87\n",
      "test epoch average loss: -3469.432373\n",
      "train epoch average loss: -2974.977092\n",
      "epoch 88\n",
      "test epoch average loss: -3484.930664\n",
      "train epoch average loss: -2987.994056\n",
      "epoch 89\n",
      "test epoch average loss: -3500.488281\n",
      "train epoch average loss: -3001.028948\n",
      "epoch 90\n",
      "test epoch average loss: -3516.048584\n",
      "train epoch average loss: -3014.080774\n",
      "epoch 91\n",
      "test epoch average loss: -3531.641846\n",
      "train epoch average loss: -3022.025676\n",
      "epoch 92\n",
      "test epoch average loss: -3533.247314\n",
      "train epoch average loss: -3023.337023\n",
      "epoch 93\n",
      "test epoch average loss: -3534.835449\n",
      "train epoch average loss: -3024.641700\n",
      "epoch 94\n",
      "test epoch average loss: -3536.410645\n",
      "train epoch average loss: -3025.940594\n",
      "epoch 95\n",
      "test epoch average loss: -3537.975342\n",
      "train epoch average loss: -3027.234434\n",
      "epoch 96\n",
      "test epoch average loss: -3539.530762\n",
      "train epoch average loss: -3028.523953\n",
      "epoch 97\n",
      "test epoch average loss: -3541.076904\n",
      "train epoch average loss: -3029.809586\n",
      "epoch 98\n",
      "test epoch average loss: -3542.616699\n",
      "train epoch average loss: -3031.091839\n",
      "epoch 99\n",
      "test epoch average loss: -3544.150146\n",
      "train epoch average loss: -3032.370723\n",
      "epoch 100\n",
      "test epoch average loss: -3545.680176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch average loss: -3033.646772\n",
      "Max iter reached\n",
      "Used ordering:  [56 16  7 24  6 31 36 14 45 10 39 47 13 28 46 51 30 25 11 44 50 33 42 41\n",
      " 55 61 26 22 19  3 34 37 21 32 59 17 27 15 20  8 58 12  0  2 54 43 38 29\n",
      " 48 53 49 62 23 63 52  5  4 18 60  9 40 57 35  1]\n"
     ]
    }
   ],
   "source": [
    "dims=64\n",
    "seed = 99\n",
    "\n",
    "args = arguments(nin=dims, nout=dims, hiddens=[64,64], num_masks=1, resample_every=1, samples=1, batch_size = 100)\n",
    "path = \"Dataset_1_generator_params\"\n",
    "\n",
    "data, ordering = gen_data(args, seed=seed, n_samples=7000, path=path, device=device)\n",
    "\n",
    "dataset_1 = {'train':data[:5000] , 'val':data[5000:6000] , 'test':data[6000:], 'ordering':ordering }\n",
    "\n",
    "np.save('./data/dataset_1.npy',dataset_1)\n",
    "# To load use: np.load('dataset_1.npy',allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490e938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f0680a2",
   "metadata": {},
   "source": [
    "# Dataset 2, Binary high dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f4c4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "test epoch average loss: 543.602112\n",
      "train epoch average loss: 193.887854\n",
      "epoch 2\n",
      "test epoch average loss: 25.499136\n",
      "train epoch average loss: -56.322171\n",
      "epoch 3\n",
      "test epoch average loss: -18.536673\n",
      "train epoch average loss: -610.013417\n",
      "epoch 4\n",
      "test epoch average loss: -127.476807\n",
      "train epoch average loss: -3416.579019\n",
      "epoch 5\n",
      "test epoch average loss: -626.802979\n",
      "train epoch average loss: -12538.430186\n",
      "epoch 6\n",
      "test epoch average loss: -2189.637695\n",
      "train epoch average loss: -33075.960273\n",
      "epoch 7\n",
      "test epoch average loss: -5645.905273\n",
      "train epoch average loss: -69957.659648\n",
      "epoch 8\n",
      "test epoch average loss: -11624.291992\n",
      "train epoch average loss: -127591.365312\n",
      "epoch 9\n",
      "test epoch average loss: -20495.007812\n",
      "train epoch average loss: -210157.312344\n",
      "epoch 10\n",
      "test epoch average loss: -33969.769531\n",
      "train epoch average loss: -321635.882344\n",
      "epoch 11\n",
      "test epoch average loss: -52058.632812\n",
      "train epoch average loss: -465263.756875\n",
      "epoch 12\n",
      "test epoch average loss: -75548.648438\n",
      "train epoch average loss: -645155.808438\n",
      "epoch 13\n",
      "test epoch average loss: -105135.875000\n",
      "train epoch average loss: -864080.826250\n",
      "epoch 14\n",
      "test epoch average loss: -141110.359375\n",
      "train epoch average loss: -1125116.447500\n",
      "epoch 15\n",
      "test epoch average loss: -184395.593750\n",
      "train epoch average loss: -1430296.186875\n",
      "epoch 16\n",
      "test epoch average loss: -235150.062500\n",
      "train epoch average loss: -1784069.062500\n",
      "epoch 17\n",
      "test epoch average loss: -292875.312500\n",
      "train epoch average loss: -2186668.557500\n",
      "epoch 18\n",
      "test epoch average loss: -361286.062500\n",
      "train epoch average loss: -2641569.525000\n",
      "epoch 19\n",
      "test epoch average loss: -435280.062500\n",
      "train epoch average loss: -3150613.956250\n",
      "epoch 20\n",
      "test epoch average loss: -521190.781250\n",
      "train epoch average loss: -3716516.412500\n",
      "epoch 21\n",
      "test epoch average loss: -616295.437500\n",
      "train epoch average loss: -4340312.182500\n",
      "epoch 22\n",
      "test epoch average loss: -719453.750000\n",
      "train epoch average loss: -5024073.932500\n",
      "epoch 23\n",
      "test epoch average loss: -833201.187500\n",
      "train epoch average loss: -5770808.175000\n",
      "epoch 24\n",
      "test epoch average loss: -956957.562500\n",
      "train epoch average loss: -6582378.802500\n",
      "epoch 25\n",
      "test epoch average loss: -1091949.750000\n",
      "train epoch average loss: -7459862.085000\n",
      "epoch 26\n",
      "test epoch average loss: -1236728.000000\n",
      "train epoch average loss: -8403271.345000\n",
      "epoch 27\n",
      "test epoch average loss: -1396294.750000\n",
      "train epoch average loss: -9416199.235000\n",
      "epoch 28\n",
      "test epoch average loss: -1568997.625000\n",
      "train epoch average loss: -10500679.110000\n",
      "epoch 29\n",
      "test epoch average loss: -1744323.375000\n",
      "train epoch average loss: -11654954.515000\n",
      "epoch 30\n",
      "test epoch average loss: -1941815.125000\n",
      "train epoch average loss: -12882330.205000\n",
      "epoch 31\n",
      "test epoch average loss: -2144352.500000\n",
      "train epoch average loss: -14185298.995000\n",
      "epoch 32\n",
      "test epoch average loss: -2358947.250000\n",
      "train epoch average loss: -15561476.840000\n",
      "epoch 33\n",
      "test epoch average loss: -2595218.000000\n",
      "train epoch average loss: -17015694.530000\n",
      "epoch 34\n",
      "test epoch average loss: -2839684.000000\n",
      "train epoch average loss: -18546090.870000\n",
      "epoch 35\n",
      "test epoch average loss: -3098117.000000\n",
      "train epoch average loss: -20155474.970000\n",
      "epoch 36\n",
      "test epoch average loss: -3365323.500000\n",
      "train epoch average loss: -21844492.550000\n",
      "epoch 37\n",
      "test epoch average loss: -3653534.750000\n",
      "train epoch average loss: -23616264.100000\n",
      "epoch 38\n",
      "test epoch average loss: -3943544.000000\n",
      "train epoch average loss: -25466650.980000\n",
      "epoch 39\n",
      "test epoch average loss: -4261148.000000\n",
      "train epoch average loss: -27400566.890000\n",
      "epoch 40\n",
      "test epoch average loss: -4590771.000000\n",
      "train epoch average loss: -29418787.960000\n",
      "epoch 41\n",
      "test epoch average loss: -4935064.000000\n",
      "train epoch average loss: -31521362.780000\n",
      "epoch 42\n",
      "test epoch average loss: -5283971.000000\n",
      "train epoch average loss: -33707600.300000\n",
      "epoch 43\n",
      "test epoch average loss: -5659285.500000\n",
      "train epoch average loss: -35983308.940000\n",
      "epoch 44\n",
      "test epoch average loss: -6034737.000000\n",
      "train epoch average loss: -38344289.160000\n",
      "epoch 45\n",
      "test epoch average loss: -6448642.500000\n",
      "train epoch average loss: -40795617.580000\n",
      "epoch 46\n",
      "test epoch average loss: -6854272.500000\n",
      "train epoch average loss: -42437210.020000\n",
      "epoch 47\n",
      "test epoch average loss: -6891760.000000\n",
      "train epoch average loss: -42694265.980000\n",
      "epoch 48\n",
      "test epoch average loss: -6929018.000000\n",
      "train epoch average loss: -42940729.880000\n",
      "epoch 49\n",
      "test epoch average loss: -6966941.500000\n",
      "train epoch average loss: -43178949.940000\n",
      "epoch 50\n",
      "test epoch average loss: -7003502.000000\n",
      "train epoch average loss: -43410765.460000\n",
      "epoch 51\n",
      "test epoch average loss: -7040459.500000\n",
      "train epoch average loss: -43637501.300000\n",
      "epoch 52\n",
      "test epoch average loss: -7077402.000000\n",
      "train epoch average loss: -43859937.000000\n",
      "epoch 53\n",
      "test epoch average loss: -7113583.000000\n",
      "train epoch average loss: -44078604.960000\n",
      "epoch 54\n",
      "test epoch average loss: -7150248.000000\n",
      "train epoch average loss: -44293998.120000\n",
      "epoch 55\n",
      "test epoch average loss: -7186163.000000\n",
      "train epoch average loss: -44506562.220000\n",
      "epoch 56\n",
      "test epoch average loss: -7221059.500000\n",
      "train epoch average loss: -44716605.700000\n",
      "epoch 57\n",
      "test epoch average loss: -7255520.000000\n",
      "train epoch average loss: -44924436.420000\n",
      "epoch 58\n",
      "test epoch average loss: -7289340.000000\n",
      "train epoch average loss: -45130337.200000\n",
      "epoch 59\n",
      "test epoch average loss: -7323769.500000\n",
      "train epoch average loss: -45334484.240000\n",
      "epoch 60\n",
      "test epoch average loss: -7357303.500000\n",
      "train epoch average loss: -45537171.500000\n",
      "epoch 61\n",
      "test epoch average loss: -7391091.000000\n",
      "train epoch average loss: -45738484.100000\n",
      "epoch 62\n",
      "test epoch average loss: -7424419.000000\n",
      "train epoch average loss: -45938541.320000\n",
      "epoch 63\n",
      "test epoch average loss: -7457241.500000\n",
      "train epoch average loss: -46137545.240000\n",
      "epoch 64\n",
      "test epoch average loss: -7489688.000000\n",
      "train epoch average loss: -46335600.380000\n",
      "epoch 65\n",
      "test epoch average loss: -7522497.000000\n",
      "train epoch average loss: -46532701.820000\n",
      "epoch 66\n",
      "test epoch average loss: -7554782.000000\n",
      "train epoch average loss: -46729106.540000\n",
      "epoch 67\n",
      "test epoch average loss: -7587539.000000\n",
      "train epoch average loss: -46924848.260000\n",
      "epoch 68\n",
      "test epoch average loss: -7620222.500000\n",
      "train epoch average loss: -47119938.160000\n",
      "epoch 69\n",
      "test epoch average loss: -7652068.500000\n",
      "train epoch average loss: -47314582.480000\n",
      "epoch 70\n",
      "test epoch average loss: -7684356.500000\n",
      "train epoch average loss: -47508710.740000\n",
      "epoch 71\n",
      "test epoch average loss: -7716969.000000\n",
      "train epoch average loss: -47702437.520000\n",
      "epoch 72\n",
      "test epoch average loss: -7748375.000000\n",
      "train epoch average loss: -47895881.960000\n",
      "epoch 73\n",
      "test epoch average loss: -7780198.000000\n",
      "train epoch average loss: -48089041.100000\n",
      "epoch 74\n",
      "test epoch average loss: -7811831.000000\n",
      "train epoch average loss: -48282085.760000\n",
      "epoch 75\n",
      "test epoch average loss: -7844097.000000\n",
      "train epoch average loss: -48474797.780000\n",
      "epoch 76\n",
      "test epoch average loss: -7875838.500000\n",
      "train epoch average loss: -48667392.220000\n",
      "epoch 77\n",
      "test epoch average loss: -7907977.000000\n",
      "train epoch average loss: -48859839.640000\n",
      "epoch 78\n",
      "test epoch average loss: -7939579.500000\n",
      "train epoch average loss: -49052148.580000\n",
      "epoch 79\n",
      "test epoch average loss: -7971914.500000\n",
      "train epoch average loss: -49244562.960000\n",
      "epoch 80\n",
      "test epoch average loss: -8003549.500000\n",
      "train epoch average loss: -49436929.540000\n",
      "epoch 81\n",
      "test epoch average loss: -8035681.500000\n",
      "train epoch average loss: -49629252.680000\n",
      "epoch 82\n",
      "test epoch average loss: -8067431.500000\n",
      "train epoch average loss: -49821626.200000\n",
      "epoch 83\n",
      "test epoch average loss: -8099681.000000\n",
      "train epoch average loss: -50014100.120000\n",
      "epoch 84\n",
      "test epoch average loss: -8131085.500000\n",
      "train epoch average loss: -50206629.760000\n",
      "epoch 85\n",
      "test epoch average loss: -8163278.000000\n",
      "train epoch average loss: -50399245.620000\n",
      "epoch 86\n",
      "test epoch average loss: -8194551.000000\n",
      "train epoch average loss: -50591944.480000\n",
      "epoch 87\n",
      "test epoch average loss: -8226938.000000\n",
      "train epoch average loss: -50784974.380000\n",
      "epoch 88\n",
      "test epoch average loss: -8258593.000000\n",
      "train epoch average loss: -50977992.660000\n",
      "epoch 89\n",
      "test epoch average loss: -8290837.000000\n",
      "train epoch average loss: -51171258.180000\n",
      "epoch 90\n",
      "test epoch average loss: -8323607.000000\n",
      "train epoch average loss: -51364715.100000\n",
      "epoch 91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch average loss: -8355242.500000\n",
      "train epoch average loss: -51491271.340000\n",
      "epoch 92\n",
      "test epoch average loss: -8358414.500000\n",
      "train epoch average loss: -51510929.040000\n",
      "epoch 93\n",
      "test epoch average loss: -8361548.500000\n",
      "train epoch average loss: -51530414.700000\n",
      "epoch 94\n",
      "test epoch average loss: -8364215.500000\n",
      "train epoch average loss: -51549628.180000\n",
      "epoch 95\n",
      "test epoch average loss: -8367147.500000\n",
      "train epoch average loss: -51568549.500000\n",
      "epoch 96\n",
      "test epoch average loss: -8370823.000000\n",
      "train epoch average loss: -51587672.840000\n",
      "epoch 97\n",
      "test epoch average loss: -8373442.500000\n",
      "train epoch average loss: -51606778.940000\n",
      "epoch 98\n",
      "test epoch average loss: -8376455.500000\n",
      "train epoch average loss: -51626046.840000\n",
      "epoch 99\n",
      "test epoch average loss: -8379588.500000\n",
      "train epoch average loss: -51645085.300000\n",
      "epoch 100\n",
      "test epoch average loss: -8382441.500000\n",
      "train epoch average loss: -51663932.960000\n",
      "Max iter reached\n",
      "Used ordering:  [372 728 476   8 224 187 567 712 680 566 160 265 310 663 138 251 422 750\n",
      " 654 145 184 320 404 118 579 734 117 510 371 497  53 321 450 676 389 394\n",
      " 144 563 280 764 171 186 419  80  56 112 543 495 658 107 383 520 761 258\n",
      " 335  15 740 770 222 185 709 256 550 528  61 500 399 498 578 391 333  88\n",
      " 729 304 116 259  86 101  97 482  23 757  76 316 540 669 113 508 426 589\n",
      " 351 103 267 665 502 220 461 434 347 469 417 182 503 217 148 179 406  10\n",
      " 710 176 130 197 587 269 164 667 155  37 178 158  33  36 322 231 591 100\n",
      " 638 753 132 188 330 211 473 206  52 463 534 583 478 459 725 738 318 233\n",
      " 281 141 720 105 324 490 636 565 487 378 692 307 397  98  17 717 772  32\n",
      " 688 506 359 696 102 153 341 501 677 255 771 401 742  49 362 704 670 242\n",
      " 699 559 429 162 701 735 268 721 454 541 290 301 156 262 660 393 240  29\n",
      " 373 644 732 135 759  50 448 412 241 733 673 656 438 314 194 294 627 382\n",
      " 584  90 300 270 342 659  60 111 152 555 439 640 376 748 743 610 119 423\n",
      " 165 126 360 229 134 350 363 432   3 484 539 689 415 142  73  68 384 590\n",
      " 690 183 683 574 532 762 518 504 308 315 348 477 278 172   7 594 253 468\n",
      " 671 208  28 749 237 345 334 722  54 626 455 346 522 462 357 305 592 666\n",
      " 203 741 679 536  55 282  51 436 221  75 377 731 456 612 744 452 167 379\n",
      " 524 395 635 575 449 272  20 287 598 374 633 140 244 343 672 511 312 191\n",
      " 416 248 223 291 600  48 271  69 277 737 614 285 313 549  70 370 505  78\n",
      " 327  42  39 381 535 588 526 573 491 646 606 599 219 283 215 189 245 339\n",
      " 483 238 442 569 515 723 125 593 475 154 576 460 645 115 136 302 628 108\n",
      " 767  38 428 768   1  81 216  74 396 781 470 385 243 727 309 632 408 657\n",
      " 122 366 556 618 624 774 254 496 568  92 586 694 611 400  91 596 486  14\n",
      " 369 298   6 595 354 458 260 163 230 651 106 686 499 328 190 553 471 668\n",
      " 212 631 296 687 181 517 609 547 637 398  13 446 625 311 647 444 336 613\n",
      " 572 228 649 239 123 716 453 778 634  99 353 766 289 121 195 319 193 577\n",
      " 368 356 124 765 557 608  84 402  16 736 775  59 367 317  12 110 713 615\n",
      " 218 597 435 466 392 349 607  89 303 622 681 235 358 601 409  34 754 210\n",
      " 236  47 623 388 420 726  77 133  11 413 493  58 580 513  72 655 521 441\n",
      " 225   5 168 641 724 525 196 711  46  45 650 445 286 585 332  21  62 175\n",
      " 706 114 410 166 177 530 297 147 582 674 380 570 533 407 161 693  66 375\n",
      " 662 128 564 151 169 104 411 773 390 782 691 425 747  64 702  41 561  40\n",
      " 714 249 602 481 488 352 173 202 131 365 780 523 519  83 685 465 204 205\n",
      " 629 323  31  25  94 479 146 227 252  44  22 703 139 325 292 457 751 274\n",
      "  96 430 698 494 234 284 200 246  63 664 443 745 150 129 143 427 263 769\n",
      " 247 605 639 266  82 295 299 755 558  85  19 485 529 562 174 760 157 261\n",
      "   4 198 783  30 338  18 293 170 616 264 440 331 527 257 653 405 509 137\n",
      " 414   0  57 779 326 433 546  87 604 159  67 684 538 545 746 120 149 288\n",
      " 763 516 643 652 276 551  27 464 109 682 548 718 739  79 226 617 431 421\n",
      " 552 472 480 581 403 730 361 752 467 697 675 715 700 355 512 560 492 705\n",
      " 642 571 678 273 192  93  95  26 619  24 621 707 209 279 424 544 451 207\n",
      " 776 344 364 199 507 275 756 418 620  35 127 531 695 337 232 214 537 437\n",
      "  43 306 250 648 542 630 213 661   9 758 201 340 777 719 387 386 329   2\n",
      " 514 489  71 708  65 603 447 180 554 474]\n"
     ]
    }
   ],
   "source": [
    "dims = 784\n",
    "seed = 98\n",
    "\n",
    "args = arguments(nin=dims, nout=dims, hiddens=[784,784], num_masks=1, resample_every=1, samples=1, batch_size = 100)\n",
    "path = \"Dataset_2_generator_params\"\n",
    "\n",
    "data, ordering = gen_data(args, seed=seed, n_samples=7000, path=path, device=device)\n",
    "\n",
    "dataset_2 = {'train':data[:5000] , 'val':data[5000:6000] , 'test':data[6000:], 'ordering':ordering }\n",
    "\n",
    "np.save('./data/dataset_2.npy',dataset_2)\n",
    "# To load use: np.load('dataset_2.npy',allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b5735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a7282b4",
   "metadata": {},
   "source": [
    "# Dataset 3, Gaussian low dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57078311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "test epoch average loss: 90.963387\n",
      "train epoch average loss: 91.046571\n",
      "epoch 2\n",
      "test epoch average loss: 90.686455\n",
      "train epoch average loss: 90.919477\n",
      "epoch 3\n",
      "test epoch average loss: 90.657906\n",
      "train epoch average loss: 90.888057\n",
      "epoch 4\n",
      "test epoch average loss: 90.651627\n",
      "train epoch average loss: 90.867535\n",
      "epoch 5\n",
      "test epoch average loss: 90.652046\n",
      "train epoch average loss: 90.847623\n",
      "epoch 6\n",
      "test epoch average loss: 90.654800\n",
      "train epoch average loss: 90.825707\n",
      "epoch 7\n",
      "test epoch average loss: 90.662399\n",
      "train epoch average loss: 90.801705\n",
      "epoch 8\n",
      "test epoch average loss: 90.674774\n",
      "train epoch average loss: 90.775851\n",
      "epoch 9\n",
      "test epoch average loss: 90.689529\n",
      "train epoch average loss: 90.748833\n",
      "epoch 10\n",
      "test epoch average loss: 90.710388\n",
      "train epoch average loss: 90.721465\n",
      "epoch 11\n",
      "test epoch average loss: 90.733543\n",
      "train epoch average loss: 90.693671\n",
      "epoch 12\n",
      "test epoch average loss: 90.763718\n",
      "train epoch average loss: 90.665856\n",
      "epoch 13\n",
      "test epoch average loss: 90.793846\n",
      "train epoch average loss: 90.638958\n",
      "epoch 14\n",
      "test epoch average loss: 90.825958\n",
      "train epoch average loss: 90.613025\n",
      "epoch 15\n",
      "test epoch average loss: 90.858513\n",
      "train epoch average loss: 90.587712\n",
      "epoch 16\n",
      "test epoch average loss: 90.890175\n",
      "train epoch average loss: 90.563397\n",
      "epoch 17\n",
      "test epoch average loss: 90.921463\n",
      "train epoch average loss: 90.539460\n",
      "epoch 18\n",
      "test epoch average loss: 90.955391\n",
      "train epoch average loss: 90.516738\n",
      "epoch 19\n",
      "test epoch average loss: 90.985390\n",
      "train epoch average loss: 90.494726\n",
      "epoch 20\n",
      "test epoch average loss: 91.015991\n",
      "train epoch average loss: 90.473819\n",
      "epoch 21\n",
      "test epoch average loss: 91.046928\n",
      "train epoch average loss: 90.454354\n",
      "epoch 22\n",
      "test epoch average loss: 91.075134\n",
      "train epoch average loss: 90.435914\n",
      "epoch 23\n",
      "test epoch average loss: 91.102440\n",
      "train epoch average loss: 90.417791\n",
      "epoch 24\n",
      "test epoch average loss: 91.127586\n",
      "train epoch average loss: 90.400715\n",
      "epoch 25\n",
      "test epoch average loss: 91.148903\n",
      "train epoch average loss: 90.384477\n",
      "epoch 26\n",
      "test epoch average loss: 91.174042\n",
      "train epoch average loss: 90.368861\n",
      "epoch 27\n",
      "test epoch average loss: 91.200645\n",
      "train epoch average loss: 90.354004\n",
      "epoch 28\n",
      "test epoch average loss: 91.227455\n",
      "train epoch average loss: 90.339970\n",
      "epoch 29\n",
      "test epoch average loss: 91.250679\n",
      "train epoch average loss: 90.326327\n",
      "epoch 30\n",
      "test epoch average loss: 91.273376\n",
      "train epoch average loss: 90.313362\n",
      "epoch 31\n",
      "test epoch average loss: 91.295097\n",
      "train epoch average loss: 90.300727\n",
      "epoch 32\n",
      "test epoch average loss: 91.319786\n",
      "train epoch average loss: 90.289035\n",
      "epoch 33\n",
      "test epoch average loss: 91.336815\n",
      "train epoch average loss: 90.277215\n",
      "epoch 34\n",
      "test epoch average loss: 91.365425\n",
      "train epoch average loss: 90.266347\n",
      "Early stopping due to no validation improvement\n",
      "Used ordering:  [27 33 48 32 37 11  2 55  9 59 34 23  0 31 57  6 22 36  8 42 63  1 40 21\n",
      " 17 30 15 39 58 12 10 46 49 19 61 43 38 25  3 45 24 16 50 13 14 62 47 54\n",
      " 52 44 29 20 56 18  4  5 60 28  7 53 51 41 35 26]\n"
     ]
    }
   ],
   "source": [
    "dims=64\n",
    "seed = 97\n",
    "\n",
    "args = arguments(nin=dims, nout=2*dims, hiddens=[64,64], num_masks=1, resample_every=1, samples=1, batch_size = 100)\n",
    "path = \"Dataset_3_generator_params\"\n",
    "\n",
    "data, ordering = gen_data(args, seed=seed, n_samples=7000, path=path, device=device)\n",
    "\n",
    "dataset_3 = {'train':data[:5000] , 'val':data[5000:6000] , 'test':data[6000:], 'ordering':ordering }\n",
    "\n",
    "np.save('./data/dataset_3.npy',dataset_3)\n",
    "# To load use: np.load('dataset_3.npy',allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332af97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e49911c7",
   "metadata": {},
   "source": [
    "# Dataset 4, Gaussian high dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7510f371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "test epoch average loss: 1111.590454\n",
      "train epoch average loss: 1112.438884\n",
      "epoch 2\n",
      "test epoch average loss: 1111.204346\n",
      "train epoch average loss: 1111.233608\n",
      "epoch 3\n",
      "test epoch average loss: 1111.435669\n",
      "train epoch average loss: 1108.444475\n",
      "epoch 4\n",
      "test epoch average loss: 1112.405273\n",
      "train epoch average loss: 1103.135005\n",
      "epoch 5\n",
      "test epoch average loss: 1114.431519\n",
      "train epoch average loss: 1096.914731\n",
      "epoch 6\n",
      "test epoch average loss: 1118.440796\n",
      "train epoch average loss: 1090.794753\n",
      "epoch 7\n",
      "test epoch average loss: 1124.294067\n",
      "train epoch average loss: 1084.800774\n",
      "epoch 8\n",
      "test epoch average loss: 1132.665527\n",
      "train epoch average loss: 1079.550964\n",
      "epoch 9\n",
      "test epoch average loss: 1138.973022\n",
      "train epoch average loss: 1074.017271\n",
      "epoch 10\n",
      "test epoch average loss: 1149.698853\n",
      "train epoch average loss: 1068.632083\n",
      "epoch 11\n",
      "test epoch average loss: 1161.715576\n",
      "train epoch average loss: 1064.535129\n",
      "epoch 12\n",
      "test epoch average loss: 1177.702515\n",
      "train epoch average loss: 1058.770945\n",
      "epoch 13\n",
      "test epoch average loss: 1195.527710\n",
      "train epoch average loss: 1053.893499\n",
      "epoch 14\n",
      "test epoch average loss: 1210.242920\n",
      "train epoch average loss: 1050.083594\n",
      "epoch 15\n",
      "test epoch average loss: 1221.182007\n",
      "train epoch average loss: 1046.442710\n",
      "epoch 16\n",
      "test epoch average loss: 1237.766846\n",
      "train epoch average loss: 1042.215688\n",
      "epoch 17\n",
      "test epoch average loss: 1256.792236\n",
      "train epoch average loss: 1038.291018\n",
      "epoch 18\n",
      "test epoch average loss: 1263.802368\n",
      "train epoch average loss: 1034.687557\n",
      "epoch 19\n",
      "test epoch average loss: 1284.874878\n",
      "train epoch average loss: 1032.115192\n",
      "epoch 20\n",
      "test epoch average loss: 1290.139404\n",
      "train epoch average loss: 1030.053038\n",
      "epoch 21\n",
      "test epoch average loss: 1314.548462\n",
      "train epoch average loss: 1024.063589\n",
      "epoch 22\n",
      "test epoch average loss: 1361.535156\n",
      "train epoch average loss: 1020.540332\n",
      "epoch 23\n",
      "test epoch average loss: 1372.211426\n",
      "train epoch average loss: 1019.283721\n",
      "epoch 24\n",
      "test epoch average loss: 1370.533447\n",
      "train epoch average loss: 1016.974971\n",
      "epoch 25\n",
      "test epoch average loss: 1395.092041\n",
      "train epoch average loss: 1013.172775\n",
      "epoch 26\n",
      "test epoch average loss: 1399.037964\n",
      "train epoch average loss: 1011.378284\n",
      "epoch 27\n",
      "test epoch average loss: 1381.427002\n",
      "train epoch average loss: 1009.598999\n",
      "epoch 28\n",
      "test epoch average loss: 1389.126831\n",
      "train epoch average loss: 1007.027325\n",
      "epoch 29\n",
      "test epoch average loss: 1405.536865\n",
      "train epoch average loss: 1005.570723\n",
      "epoch 30\n",
      "test epoch average loss: 1395.687134\n",
      "train epoch average loss: 1002.057319\n",
      "epoch 31\n",
      "test epoch average loss: 1393.679688\n",
      "train epoch average loss: 999.982993\n",
      "epoch 32\n",
      "test epoch average loss: 1402.629639\n",
      "train epoch average loss: 998.970020\n",
      "epoch 33\n",
      "test epoch average loss: 1386.797241\n",
      "train epoch average loss: 997.614813\n",
      "epoch 34\n",
      "test epoch average loss: 1377.404419\n",
      "train epoch average loss: 996.390392\n",
      "epoch 35\n",
      "test epoch average loss: 1389.903564\n",
      "train epoch average loss: 993.134447\n",
      "epoch 36\n",
      "test epoch average loss: 1388.796997\n",
      "train epoch average loss: 991.992346\n",
      "epoch 37\n",
      "test epoch average loss: 1383.109497\n",
      "train epoch average loss: 991.316149\n",
      "epoch 38\n",
      "test epoch average loss: 1380.333130\n",
      "train epoch average loss: 988.970737\n",
      "epoch 39\n",
      "test epoch average loss: 1383.402954\n",
      "train epoch average loss: 988.815695\n",
      "epoch 40\n",
      "test epoch average loss: 1377.440674\n",
      "train epoch average loss: 986.416248\n",
      "epoch 41\n",
      "test epoch average loss: 1378.719971\n",
      "train epoch average loss: 984.052025\n",
      "epoch 42\n",
      "test epoch average loss: 1385.313110\n",
      "train epoch average loss: 983.208093\n",
      "epoch 43\n",
      "test epoch average loss: 1397.650757\n",
      "train epoch average loss: 982.000088\n",
      "epoch 44\n",
      "test epoch average loss: 1374.468384\n",
      "train epoch average loss: 981.445465\n",
      "epoch 45\n",
      "test epoch average loss: 1378.565918\n",
      "train epoch average loss: 979.849590\n",
      "epoch 46\n",
      "test epoch average loss: 1391.007812\n",
      "train epoch average loss: 978.305879\n",
      "epoch 47\n",
      "test epoch average loss: 1431.326538\n",
      "train epoch average loss: 966.366584\n",
      "epoch 48\n",
      "test epoch average loss: 1491.613770\n",
      "train epoch average loss: 961.427008\n",
      "epoch 49\n",
      "test epoch average loss: 1525.711914\n",
      "train epoch average loss: 957.867911\n",
      "epoch 50\n",
      "test epoch average loss: 1552.886230\n",
      "train epoch average loss: 955.012213\n",
      "epoch 51\n",
      "test epoch average loss: 1577.157349\n",
      "train epoch average loss: 952.630674\n",
      "epoch 52\n",
      "test epoch average loss: 1600.076660\n",
      "train epoch average loss: 950.589056\n",
      "epoch 53\n",
      "test epoch average loss: 1622.110962\n",
      "train epoch average loss: 948.790243\n",
      "epoch 54\n",
      "test epoch average loss: 1643.797241\n",
      "train epoch average loss: 947.172152\n",
      "epoch 55\n",
      "test epoch average loss: 1665.250488\n",
      "train epoch average loss: 945.699584\n",
      "epoch 56\n",
      "test epoch average loss: 1686.995972\n",
      "train epoch average loss: 944.330784\n",
      "epoch 57\n",
      "test epoch average loss: 1709.755981\n",
      "train epoch average loss: 943.054858\n",
      "epoch 58\n",
      "test epoch average loss: 1733.019531\n",
      "train epoch average loss: 941.846942\n",
      "epoch 59\n",
      "test epoch average loss: 1757.738647\n",
      "train epoch average loss: 940.696923\n",
      "epoch 60\n",
      "test epoch average loss: 1783.726929\n",
      "train epoch average loss: 939.610983\n",
      "epoch 61\n",
      "test epoch average loss: 1810.812866\n",
      "train epoch average loss: 938.631720\n",
      "epoch 62\n",
      "test epoch average loss: 1833.686768\n",
      "train epoch average loss: 937.801295\n",
      "epoch 63\n",
      "test epoch average loss: 1855.589478\n",
      "train epoch average loss: 936.903481\n",
      "epoch 64\n",
      "test epoch average loss: 1877.142334\n",
      "train epoch average loss: 935.980651\n",
      "epoch 65\n",
      "test epoch average loss: 1904.830933\n",
      "train epoch average loss: 935.152410\n",
      "epoch 66\n",
      "test epoch average loss: 1934.629883\n",
      "train epoch average loss: 934.669078\n",
      "epoch 67\n",
      "test epoch average loss: 1936.961548\n",
      "train epoch average loss: 934.395586\n",
      "epoch 68\n",
      "test epoch average loss: 1920.500366\n",
      "train epoch average loss: 933.634363\n",
      "epoch 69\n",
      "test epoch average loss: 1930.766846\n",
      "train epoch average loss: 933.152351\n",
      "epoch 70\n",
      "test epoch average loss: 1941.201294\n",
      "train epoch average loss: 932.754929\n",
      "epoch 71\n",
      "test epoch average loss: 1962.439209\n",
      "train epoch average loss: 931.876986\n",
      "epoch 72\n",
      "test epoch average loss: 1995.700684\n",
      "train epoch average loss: 930.613682\n",
      "epoch 73\n",
      "test epoch average loss: 2039.955811\n",
      "train epoch average loss: 929.675551\n",
      "epoch 74\n",
      "test epoch average loss: 2083.348877\n",
      "train epoch average loss: 929.057427\n",
      "epoch 75\n",
      "test epoch average loss: 2123.740967\n",
      "train epoch average loss: 928.773073\n",
      "epoch 76\n",
      "test epoch average loss: 2139.676514\n",
      "train epoch average loss: 928.900500\n",
      "epoch 77\n",
      "test epoch average loss: 2111.132568\n",
      "train epoch average loss: 928.946764\n",
      "epoch 78\n",
      "test epoch average loss: 2108.292480\n",
      "train epoch average loss: 928.968154\n",
      "epoch 79\n",
      "test epoch average loss: 2108.817139\n",
      "train epoch average loss: 929.274202\n",
      "epoch 80\n",
      "test epoch average loss: 2083.691162\n",
      "train epoch average loss: 927.526191\n",
      "epoch 81\n",
      "test epoch average loss: 2121.211914\n",
      "train epoch average loss: 926.223324\n",
      "epoch 82\n",
      "test epoch average loss: 2197.712891\n",
      "train epoch average loss: 925.163987\n",
      "epoch 83\n",
      "test epoch average loss: 2284.836670\n",
      "train epoch average loss: 924.406270\n",
      "epoch 84\n",
      "test epoch average loss: 2353.452148\n",
      "train epoch average loss: 923.944266\n",
      "epoch 85\n",
      "test epoch average loss: 2390.393799\n",
      "train epoch average loss: 924.211299\n",
      "epoch 86\n",
      "test epoch average loss: 2359.450684\n",
      "train epoch average loss: 925.998484\n",
      "epoch 87\n",
      "test epoch average loss: 2199.878174\n",
      "train epoch average loss: 926.633005\n",
      "epoch 88\n",
      "test epoch average loss: 2151.162109\n",
      "train epoch average loss: 924.612468\n",
      "epoch 89\n",
      "test epoch average loss: 2224.626709\n",
      "train epoch average loss: 922.879420\n",
      "epoch 90\n",
      "test epoch average loss: 2320.052979\n",
      "train epoch average loss: 921.566426\n",
      "epoch 91\n",
      "test epoch average loss: 2421.288818\n",
      "train epoch average loss: 920.390503\n",
      "epoch 92\n",
      "test epoch average loss: 2429.034424\n",
      "train epoch average loss: 919.673979\n",
      "epoch 93\n",
      "test epoch average loss: 2450.175049\n",
      "train epoch average loss: 918.996510\n",
      "epoch 94\n",
      "test epoch average loss: 2475.254639\n",
      "train epoch average loss: 918.565472\n",
      "epoch 95\n",
      "test epoch average loss: 2499.880615\n",
      "train epoch average loss: 918.225878\n",
      "epoch 96\n",
      "test epoch average loss: 2523.682617\n",
      "train epoch average loss: 917.939398\n",
      "epoch 97\n",
      "test epoch average loss: 2546.883057\n",
      "train epoch average loss: 917.689948\n",
      "epoch 98\n",
      "test epoch average loss: 2569.762695\n",
      "train epoch average loss: 917.467368\n",
      "epoch 99\n",
      "test epoch average loss: 2592.203857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch average loss: 917.265297\n",
      "epoch 100\n",
      "test epoch average loss: 2614.341309\n",
      "train epoch average loss: 917.079675\n",
      "Max iter reached\n",
      "Used ordering:  [352 194 294 583 214 136  69  74 681 400  30  57 625   4 452 763 432 714\n",
      "  79  20 154 479 712 612 584 652 313 221 350 680  16 234  80 606 125 663\n",
      " 498 323  49 199 104 751 358 632 635 530 329 270  92  48  63 102  51  64\n",
      " 322 253 412 158 297 617 647 598 441 385 277 759   9 285 725 529  71 746\n",
      " 723 447 288 556 545 162 684 747 666 128 611 495 656 345 250 519  53 483\n",
      " 180 197 512 138 739 206 480 315 440 418 287 664 541 554 550 298 308 354\n",
      " 473  32 537  40 428 668 254 222 520 129 499 686 476 579 118 532  59 108\n",
      " 749  86 678 177  12 692 335 227 475   7 567 220 501 576 590 388  11 215\n",
      " 420 514 711  37  76 348 572 482 396 230 542 614 768 247 682 392 442  82\n",
      " 209 528 312 292 370 737  54 264 202 552 333 343 424  97 235 113 756 540\n",
      "  87 720 622 394 410 773 338 603 437 719 252 137 715 242 518 135 134 334\n",
      " 493 760 122 624 378 638 660 257 164 478 303 249 602 683 219 534 142 299\n",
      " 398 753 770 210 616 585 290 732 695 417 414 547 461 704 649  35 377 673\n",
      " 667 730  13 691 159 761 582 748  36 444 486 535 140 147 699 327 203 318\n",
      " 339 148 109  26 637 185 726 105 391 282 261  41 107 190 555 211 353 371\n",
      " 115 599 553 633 155 248 172 619 266 742 331 397 383 636 618 236  33 293\n",
      " 718 571 644 675 382 110 455 415 273 470  77 133 639 713 366 195 267 629\n",
      " 641 260 416 557 767 132 368 374 698 367 289 204 631  65  10 778 578 745\n",
      " 175  81 558 144 389  90  42 460 589 594 521 605 153 527  39 466 166  67\n",
      " 351 610 184 403  99 362 516 207 465 508  91 269 381 503 724 272 601 623\n",
      " 505 504 145 653 225 676  47 346  83 275 543 369 307 300 244 551 314  21\n",
      " 577 733 522 560 573 596 777 517 494 429 685 575  23 643 570 365 646 171\n",
      " 165 178 321 700 694 593 192 127   3 402 355 435  14 139 198 283 548  38\n",
      " 650 130 304 309 655 271 457 152 256  19 245 167 229 262 755 738 189 640\n",
      " 310 736   0 634 384 688 213   2 196 170 451 721 187 387 278 564 151 776\n",
      " 407 123 586 239 506 764 671 781 509 581 674 464 487 531 626 774 251 762\n",
      " 772  93 100 311 301 782 689 336 305 372 160 448 208 360 231 687 419 467\n",
      "  52 161 246 462 727 226 744 240 340  95 771 511 565 224 433 597 143 401\n",
      " 696   6 752  31 497 237 406 157  44 722 630 697 436 306 536  70 562 438\n",
      " 604 450 328  46 395 330 523 179 454  72 319 316 439 679 728 258 588 735\n",
      " 717 731 168 342 716   5 740 608 672 341 702 399 662 525 223 654 574  43\n",
      " 769 458 642 491 286 544  15 693 446 356 376 757 106 191 741 357 146 472\n",
      " 568 500 409 677 613 766  29 291 539 408 411 587 743 284 705 615 176 459\n",
      " 217  27 268 538  88 232 379 259  75 546 563 149 349 645 183 181 708  34\n",
      " 502 359 156 580  28 657 120 141 690  55 449 212 477 112 665 216 710 515\n",
      " 116  85  62 169 561  60 510 456 405 453 117 114 421 375  96 670 783 669\n",
      " 592 703  22 121 484 265  68  50 361 174   1 347 489 324 182 296 200 754\n",
      " 427 661 326  17 425  73 443 559 431 471 241 600 492 295 302 150  18 393\n",
      " 426 627 524 344   8 276  89 320 243  94  58 513 488 201 205 659 651 413\n",
      "  78  98 658 750 765 775 126 325 706 373 423 620  25 595  24  45 173 734\n",
      " 218 496 281 101 363 549 263 430 163  56 569 434  61 463 607 228 707 709\n",
      " 490 729 119 274 468 238 469 279 758 526 103 255 193 233 648 332 533 701\n",
      " 404 280 186 780 591 779 621 188 131 445 337 474 380 124 485 386 111 390\n",
      " 507 317 566  66 481 609 628 364 422  84]\n"
     ]
    }
   ],
   "source": [
    "dims = 784\n",
    "seed = 96\n",
    "\n",
    "args = arguments(nin=dims, nout=2*dims, hiddens=[784,784], num_masks=1, resample_every=1, samples=1, batch_size = 100)\n",
    "path = \"Dataset_4_generator_params\"\n",
    "\n",
    "data, ordering = gen_data(args, seed=seed, n_samples=7000, path=path, device=device)\n",
    "\n",
    "dataset_4 = {'train':data[:5000] , 'val':data[5000:6000] , 'test':data[6000:], 'ordering':ordering }\n",
    "\n",
    "np.save('./data/dataset_4.npy',dataset_4)\n",
    "# To load use: np.load('dataset_4.npy',allow_pickle=True)[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5605664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf133f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc56cdd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea93682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316f195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d49de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf14601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
